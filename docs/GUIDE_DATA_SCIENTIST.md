# üìä **GUIDE DATA SCIENTIST: CSV ‚Üí Trino ‚Üí Grafana**

## üéØ **WORKFLOW COMPLET**

### **1Ô∏è‚É£ IMPORTER UN CSV DANS MINIO**

#### **Acc√®s √† MinIO:**
- **URL:** http://localhost:30901/browser/datalake
- **Login:** `minioadmin` / `minioadmin`

#### **√âtapes d'import:**
1. **Ouvrir MinIO Console**
2. **Cr√©er un bucket** (ex: `raw-data`)
3. **Uploader votre CSV** dans le bucket
4. **Noter le chemin** (ex: `s3://raw-data/mon_fichier.csv`)

---

### **2Ô∏è‚É£ R√âCUP√âRER LES DONN√âES AVEC TRINO**

#### **Option A: Dans JupyterHub (Recommand√©)**
```python
# Dans JupyterHub (http://localhost:30080)
from trino.dbapi import connect
import pandas as pd

# Connexion Trino
conn = connect(
    host='trino-coordinator.data-platform.svc.cluster.local',
    port=8080,
    user='admin'
)

# Requ√™te pour lire le CSV depuis MinIO
query = """
SELECT * FROM hive.raw_data.mon_fichier_csv
LIMIT 10
"""

# Ex√©cuter et convertir en DataFrame
df = pd.read_sql(query, conn)
print(df.head())
```

#### **Option B: Via Trino UI**
- **URL:** http://localhost:30808
- **Requ√™te:**
```sql
SELECT * FROM hive.raw_data.mon_fichier_csv
LIMIT 10;
```

---

### **3Ô∏è‚É£ CR√âER UN TABLEAU DE BORD GRAFANA**

#### **Acc√®s √† Grafana:**
- **URL:** http://localhost:30030
- **Login:** `admin` / `datamesh2024`

#### **Configuration de la source de donn√©es:**
1. **Aller dans:** Configuration ‚Üí Data Sources
2. **Ajouter:** Trino
3. **URL:** `http://trino-coordinator.data-platform.svc.cluster.local:8080`
4. **User:** `admin`
5. **Test & Save**

#### **Cr√©ation du dashboard:**
1. **Cr√©er un nouveau dashboard**
2. **Ajouter un panel**
3. **S√©lectionner Trino comme source**
4. **√âcrire votre requ√™te:**
```sql
SELECT 
    column1,
    column2,
    COUNT(*) as count
FROM hive.raw_data.mon_fichier_csv
GROUP BY column1, column2
ORDER BY count DESC
```

---

## üîß **EXEMPLE PRATIQUE COMPLET**

### **√âtape 1: Cr√©er des donn√©es d'exemple**

Dans JupyterHub, cr√©ez un notebook avec :

```python
import pandas as pd

# Cr√©er des donn√©es d'exemple
data = {
    'date': ['2025-01-01', '2025-01-02', '2025-01-03', '2025-01-04', '2025-01-05'],
    'product': ['Laptop', 'Mouse', 'Keyboard', 'Monitor', 'Laptop'],
    'sales': [1200, 25, 75, 300, 1200],
    'region': ['North', 'South', 'East', 'West', 'North'],
    'customer_id': [1, 2, 3, 4, 5]
}

df = pd.DataFrame(data)
df.to_csv('sales_data.csv', index=False)
print(df)
```

### **√âtape 2: Upload vers MinIO**

1. **Ouvrir:** http://localhost:30901/browser/datalake
2. **Login:** `minioadmin` / `minioadmin`
3. **Cr√©er bucket:** `raw-data`
4. **Uploader:** `sales_data.csv`

### **√âtape 3: Requ√™tes Trino**

Dans JupyterHub :

```python
from trino.dbapi import connect
import pandas as pd

# Connexion Trino
conn = connect(
    host='trino-coordinator.data-platform.svc.cluster.local',
    port=8080,
    user='admin'
)

# Requ√™te pour lire le CSV
query = """
SELECT * FROM hive.raw_data.sales_data_csv
LIMIT 10
"""

df = pd.read_sql(query, conn)
print(df.head())
```

### **√âtape 4: Dashboard Grafana**

1. **Ouvrir:** http://localhost:30030
2. **Login:** `admin` / `datamesh2024`
3. **Configuration ‚Üí Data Sources ‚Üí Add Trino**
4. **URL:** `http://trino-coordinator.data-platform.svc.cluster.local:8080`
5. **User:** `admin`
6. **Test & Save**

#### **Requ√™tes pour dashboard:**

**Ventes par r√©gion:**
```sql
SELECT region, SUM(sales) as total_sales
FROM hive.raw_data.sales_data_csv
GROUP BY region
ORDER BY total_sales DESC
```

**Ventes par produit:**
```sql
SELECT product, COUNT(*) as count, AVG(sales) as avg_sales
FROM hive.raw_data.sales_data_csv
GROUP BY product
ORDER BY count DESC
```

**√âvolution des ventes:**
```sql
SELECT date, SUM(sales) as daily_sales
FROM hive.raw_data.sales_data_csv
GROUP BY date
ORDER BY date
```

---

## üåê **ACC√àS AUX SERVICES**

| Service | URL | Login |
|---------|-----|-------|
| **MinIO** | http://localhost:30901 | minioadmin / minioadmin |
| **Trino UI** | http://localhost:30808 | - |
| **Grafana** | http://localhost:30030 | admin / datamesh2024 |
| **JupyterHub** | http://localhost:30080 | admin / datamesh2024 |

---

## üí° **CONSEILS PRATIQUES**

### **Pour les CSV:**
- **Format:** CSV avec en-t√™tes
- **Encodage:** UTF-8
- **S√©parateur:** Virgule (,)
- **Taille:** Pas de limite (MinIO g√®re le Big Data)

### **Pour Trino:**
- **Sch√©ma:** `hive.raw_data` pour les CSV
- **Tables:** Nom du fichier sans extension
- **Requ√™tes:** SQL standard

### **Pour Grafana:**
- **Refresh:** 5s, 1m, 5m selon vos besoins
- **Variables:** Utilisez les variables pour la flexibilit√©
- **Alertes:** Configurez des alertes sur les m√©triques importantes

---

## üöÄ **PROCHAINES √âTAPES**

1. **Explorer les donn√©es** avec Trino
2. **Cr√©er des vues** pour simplifier les requ√™tes
3. **D√©velopper des mod√®les** avec DBT
4. **Automatiser** les dashboards
5. **Mettre en place** des alertes

**Votre Data Mesh est pr√™t pour l'analyse de donn√©es ! üéâüìä**
