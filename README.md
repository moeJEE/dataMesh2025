# ğŸ—ï¸ DataMeesh Platform

**A Modern, Production-Ready Data Mesh Platform on Kubernetes**

[![Platform](https://img.shields.io/badge/Platform-Kubernetes-326CE5?logo=kubernetes)](https://kubernetes.io/)
[![Data Mesh](https://img.shields.io/badge/Architecture-Data%20Mesh-FF6B6B)](https://martinfowler.com/articles/data-mesh-principles.html)

> Complete Data Mesh implementation with federated queries, self-service analytics, data transformation, and metadata management.

---

## ğŸ¯ What is DataMeesh?

A **production-grade Data Mesh platform** demonstrating modern data engineering:

- âœ… **Domain-Oriented** - Sales & Marketing domains with clear ownership
- âœ… **Federated Queries** - Trino for cross-domain analytics
- âœ… **Self-Service** - JupyterHub for data scientists
- âœ… **Data Transformation** - DBT for ELT pipelines
- âœ… **Visualization** - Grafana dashboards
- âœ… **Data Lake** - Minio S3-compatible storage
- âœ… **Metadata Management** - Hive Metastore for data lake tables
- âœ… **Metadata Catalog** - DataHub (optional, requires 10-12GB RAM)

---

## ğŸš€ Quick Start

### Prerequisites

- Docker Desktop with Kubernetes enabled
- Python 3.8+
- 8-10GB RAM

### Deploy (One Command!)

```bash
# 1. Verify system
python setup/verify_prerequisites.py

# 2. Deploy everything
python setup/deploy_complete_stack.py
```

**Time:** ~15 minutes  
**Result:** Full Data Mesh platform ready to use!

---

## ğŸŒ Access Points

| Service | URL | Credentials |
|---------|-----|-------------|
| **JupyterHub** | http://localhost:30080 | admin / datamesh2024 |
| **Trino Web UI** | http://localhost:30808 | - |
| **Minio Console** | http://localhost:30901 | minioadmin / minioadmin |
| **Grafana** | http://localhost:30030 | admin / datamesh2024 |
| **DBT Docs** | http://localhost:30082 | - |
| **DataHub** (optional) | http://localhost:9002 | datahub / datahub |

---

## ğŸ“‚ Project Structure

```
DataMeesh/
â”œâ”€â”€ README.md                    # This file
â”‚
â”œâ”€â”€ config/                      # Kubernetes manifests
â”‚   â”œâ”€â”€ datamesh.yaml           # Core domains
â”‚   â”œâ”€â”€ minio-trino-hive.yaml   # Analytics stack
â”‚   â”œâ”€â”€ grafana.yaml            # Visualization
â”‚   â””â”€â”€ nginx-dbt-docs.yaml     # Documentation
â”‚
â”œâ”€â”€ setup/                       # Deployment scripts
â”‚   â”œâ”€â”€ verify_prerequisites.py # Check system
â”‚   â”œâ”€â”€ deploy_complete_stack.py# Deploy everything
â”‚   â”œâ”€â”€ cleanup.py              # Remove all
â”‚   â”‚
â”‚   â”œâ”€â”€ kubernetes/             # Core deployments
â”‚   â”œâ”€â”€ helm/                   # JupyterHub
â”‚   â”œâ”€â”€ trino/                  # Federated queries
â”‚   â”œâ”€â”€ grafana/                # Dashboards
â”‚   â”œâ”€â”€ dbt/                    # Data transformation
â”‚   â”œâ”€â”€ data/                   # Sample data
â”‚   â”œâ”€â”€ datahub/                # DataHub (optional)
â”‚   â””â”€â”€ docker/                 # Custom images
â”‚
â”œâ”€â”€ docs/                        # Documentation
â”‚   â”œâ”€â”€ DEPLOYMENT_GUIDE.md     # Deployment guide
â”‚   â”œâ”€â”€ CLEANUP_GUIDE.md        # Cleanup guide
â”‚   â”‚
â”‚   â”œâ”€â”€ guides/                 # User guides
â”‚   â”‚   â”œâ”€â”€ COMPLETE_GUIDE.md
â”‚   â”‚   â”œâ”€â”€ DATAHUB_GUIDE.md
â”‚   â”‚   â””â”€â”€ ADVANCED_STACK.md
â”‚   â”‚
â”‚   â”œâ”€â”€ architecture/           # Architecture docs
â”‚   â”‚   â”œâ”€â”€ DATA_MODEL.md
â”‚   â”‚   â””â”€â”€ DEPLOYMENT_STATUS.md
â”‚   â”‚
â”‚   â””â”€â”€ summaries/              # Summary reports
â”‚       â”œâ”€â”€ DEPLOYMENT_SUMMARY.md
â”‚       â””â”€â”€ FINAL_SUMMARY.md
â”‚
â”œâ”€â”€ recipes/                     # DataHub ingestion
â”‚   â”œâ”€â”€ datahub_trino_recipe.yml
â”‚   â””â”€â”€ datahub_dbt_recipe.yml
â”‚
â””â”€â”€ examples/                    # Example code
    â”œâ”€â”€ trino_queries.sql
    â””â”€â”€ jupyter_notebook_example.py
```

---

## ğŸ“ Key Features

### 1. Domain-Oriented Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Sales Domain   â”‚       â”‚Marketing Domain â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ PostgreSQL    â”‚       â”‚ â€¢ PostgreSQL    â”‚
â”‚ â€¢ REST APIs     â”‚       â”‚ â€¢ REST APIs     â”‚
â”‚ â€¢ 15 Customers  â”‚       â”‚ â€¢ 8 Campaigns   â”‚
â”‚ â€¢ 20 Orders     â”‚       â”‚ â€¢ 15 Leads      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Trino Engine  â”‚
            â”‚ Federated SQL  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Federated Queries (Trino + Hive)

Query across domains and data lake seamlessly:

```sql
-- Cross-domain: Marketing campaigns â†’ Sales revenue
SELECT 
    c.campaign_name,
    COUNT(DISTINCT l.lead_id) as leads,
    SUM(o.total_amount) as revenue
FROM marketing.public.campaigns c
JOIN marketing.public.leads l ON c.campaign_id = l.campaign_id
JOIN sales.public.customers cust ON l.email = cust.email
JOIN sales.public.orders o ON cust.customer_id = o.customer_id
GROUP BY 1;

-- Query data lake via Hive Metastore
SELECT * FROM hive.default.customer_events
WHERE event_date = CURRENT_DATE;
```

**Catalogs available:**
- `sales` - Sales PostgreSQL
- `marketing` - Marketing PostgreSQL  
- `hive` - Minio data lake (via Hive Metastore)

### 3. Self-Service Analytics (JupyterHub)

```python
from trino.dbapi import connect

conn = connect(
    host='trino-coordinator.data-platform.svc.cluster.local',
    port=8080,
    user='admin'
)

df = pd.read_sql("SELECT * FROM sales.public.customers", conn)
df.head()
```

### 4. Data Transformation (DBT)

```
Raw Data â†’ DBT Staging â†’ DBT Marts â†’ Analytics
```

**Models:**
- `stg_sales__customers` - Clean customer data
- `stg_sales__orders` - Standardized orders
- `mart_sales__customer_lifetime_value` - CLV + RFM scores

---

## ğŸ“Š Architecture

### Components

| Layer | Component | Purpose | Resources |
|-------|-----------|---------|-----------|
| **Storage** | PostgreSQL (Sales) | Customer, Order data | 256MB |
| **Storage** | PostgreSQL (Marketing) | Campaign, Lead data | 128MB |
| **Query** | Trino | Federated queries | 3GB |
| **Storage** | Minio | Data lake (S3) | 256MB |
| **Metadata** | Hive Metastore | Data lake metadata | 512MB |
| **Analytics** | JupyterHub | Notebooks | 900MB |
| **Transform** | DBT | Data pipelines | - |
| **Visualization** | Grafana | Dashboards | 256MB |
| **Catalog** | DataHub (optional) | Metadata | 2-3GB |

**Total:** ~6.5GB (or ~9GB with DataHub)

---

## ğŸ”§ Management Commands

```bash
# Verify prerequisites
python setup/verify_prerequisites.py

# Deploy everything
python setup/deploy_complete_stack.py

# Check status
kubectl get pods --all-namespaces

# View logs
kubectl logs -n <namespace> <pod-name>

# Clean up
python setup/cleanup.py

# Deploy DataHub (optional - requires 10-12GB RAM)
python setup/datahub/deploy_datahub.py
```

---

## ğŸ“š Documentation

| Document | Description |
|----------|-------------|
| [**Deployment Guide**](docs/DEPLOYMENT_GUIDE.md) | Step-by-step deployment |
| [**Cleanup Guide**](docs/CLEANUP_GUIDE.md) | Resource cleanup |
| [**Complete Guide**](docs/guides/COMPLETE_GUIDE.md) | Comprehensive user guide |
| [**Hive Metastore Guide**](docs/guides/HIVE_METASTORE_GUIDE.md) | Data lake metadata |
| [**Architecture**](docs/architecture/) | Technical details |
| [**Setup Details**](setup/README.md) | Setup folder guide |

---

## ğŸ¯ Use Cases

### 1. Marketing Attribution

Track leads from campaigns to revenue:

```python
query = """
SELECT 
    c.campaign_name,
    COUNT(DISTINCT l.lead_id) as leads,
    SUM(o.total_amount) as revenue
FROM marketing.public.campaigns c
JOIN marketing.public.leads l ON c.campaign_id = l.campaign_id
JOIN sales.public.customers cust ON l.email = cust.email
JOIN sales.public.orders o ON cust.customer_id = o.customer_id
GROUP BY 1
"""
df = pd.read_sql(query, trino_conn)
```

### 2. Customer Lifetime Value

```sql
SELECT 
    customer_id,
    SUM(total_amount) as lifetime_value,
    COUNT(*) as total_orders,
    CASE 
        WHEN SUM(total_amount) >= 100000 THEN 'High Value'
        ELSE 'Medium Value'
    END as segment
FROM orders
GROUP BY customer_id
```

### 3. Cross-Domain Analytics

Analyze marketing campaign impact on sales.

---

## ğŸ† What Makes This Special?

âœ… **Production-Ready**
- Resource limits & requests
- Health checks, Auto-scaling
- High availability, Security (RBAC, Secrets)

âœ… **Best Practices**
- Infrastructure as Code
- Kubernetes orchestration
- Modern data stack

âœ… **Complete**
- End-to-end platform
- Sample data included
- Full documentation

âœ… **Portable**
- Cross-platform (Windows, WSL, macOS, Linux)
- One-command deployment
- Easy to redeploy

---

## ğŸ§¹ Cleanup

```bash
# Standard cleanup
python setup/cleanup.py

# Deep Docker cleanup (removes ALL Docker resources)
python setup/cleanup_docker_cache.py
```

---

## ğŸ¤ Contributing

This is a demonstration project. Feel free to:
- Fork and extend
- Add more domains
- Implement additional DBT models
- Create more dashboards

---

## ğŸ“ Support

- **Deployment issues?** â†’ Check [Deployment Guide](docs/DEPLOYMENT_GUIDE.md)
- **Cleanup questions?** â†’ Check [Cleanup Guide](docs/CLEANUP_GUIDE.md)
- **Usage questions?** â†’ Check [Complete Guide](docs/guides/COMPLETE_GUIDE.md)

---

## ğŸ“„ License

MIT License - See LICENSE file for details

---

## ğŸ™ Built With

Amazing open-source technologies:
- [Kubernetes](https://kubernetes.io/)
- [Trino](https://trino.io/)
- [Apache Hive](https://hive.apache.org/)
- [JupyterHub](https://jupyter.org/hub)
- [DBT](https://www.getdbt.com/)
- [Grafana](https://grafana.com/)
- [Minio](https://min.io/)

---

**Ready to explore modern data engineering?** ğŸš€

```bash
python setup/deploy_complete_stack.py
```
