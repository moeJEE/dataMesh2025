# ğŸ”§ DataMeesh - Setup Directory

**Portable, cross-platform deployment scripts for the entire Data Mesh platform**

---

## ğŸ“‚ Directory Structure

```
setup/
â”œâ”€â”€ ğŸ“„ verify_prerequisites.py     # Verify all requirements
â”œâ”€â”€ ğŸ“„ deploy_complete_stack.py    # Deploy everything (ONE COMMAND!)
â”œâ”€â”€ ğŸ“„ cleanup.py                  # Remove all resources
â”œâ”€â”€ ğŸ“„ cleanup_docker_cache.py     # Deep clean Docker cache
â”œâ”€â”€ ğŸ“„ README.md                   # This file
â”‚
â”œâ”€â”€ âš™ï¸  kubernetes/                 # Kubernetes deployments
â”‚   â””â”€â”€ deploy_k8s.py              # Deploy core domains
â”‚
â”œâ”€â”€ âˆ  helm/                        # Helm charts
â”‚   â”œâ”€â”€ install_helm.py            # Install Helm
â”‚   â”œâ”€â”€ deploy_jupyterhub.py       # Deploy JupyterHub
â”‚   â””â”€â”€ jupyterhub-values.yaml     # Helm values
â”‚
â”œâ”€â”€ ğŸ”® trino/                       # Trino stack
â”‚   â””â”€â”€ deploy_trino.py            # Deploy Trino + Minio + Hive
â”‚
â”œâ”€â”€ ğŸ“Š grafana/                     # Grafana dashboards
â”‚   â””â”€â”€ deploy_grafana.py          # Deploy Grafana + Nginx
â”‚
â”œâ”€â”€ ğŸ”§ dbt/                         # DBT project
â”‚   â”œâ”€â”€ setup_dbt.py               # Setup DBT in JupyterHub
â”‚   â”œâ”€â”€ dbt_project.yml            # DBT configuration
â”‚   â”œâ”€â”€ profiles.yml               # Connection profiles
â”‚   â””â”€â”€ models/                    # DBT models
â”‚       â”œâ”€â”€ staging/               # Staging models (views)
â”‚       â””â”€â”€ marts/                 # Mart models (tables)
â”‚
â”œâ”€â”€ ğŸ“¦ data/                        # Sample data
â”‚   â””â”€â”€ load_sample_data.py        # Load test data
â”‚
â”œâ”€â”€ ğŸ—‚ï¸  datahub/                    # DataHub (optional)
â”‚   â”œâ”€â”€ deploy_datahub.py          # Deploy DataHub
â”‚   â””â”€â”€ README.md                  # DataHub guide
â”‚
â””â”€â”€ ğŸ³ docker/                      # Docker images
    â””â”€â”€ Dockerfile.jupyterhub-dbt  # Custom JupyterHub image
```

---

## ğŸš€ Quick Start

### Option 1: Deploy Everything (Recommended)

```bash
# 1. Verify prerequisites
python setup/verify_prerequisites.py

# 2. Deploy the entire platform
python setup/deploy_complete_stack.py

# Done! Access at http://localhost:30080
```

### Option 2: Step-by-Step Deployment

```bash
# 1. Verify system
python setup/verify_prerequisites.py

# 2. Deploy core Kubernetes resources
python setup/kubernetes/deploy_k8s.py

# 3. Install Helm
python setup/helm/install_helm.py

# 4. Deploy JupyterHub
python setup/helm/deploy_jupyterhub.py

# 5. Deploy Trino stack
python setup/trino/deploy_trino.py

# 6. Deploy Grafana
python setup/grafana/deploy_grafana.py

# 7. Load sample data
python setup/data/load_sample_data.py

# 8. (Optional) Setup DBT
python setup/dbt/setup_dbt.py

# 9. (Optional) Deploy DataHub - Requires 10-12GB RAM
python setup/datahub/deploy_datahub.py
```

---

## ğŸ“‹ Script Details

### ğŸ” **verify_prerequisites.py**

Verifies all requirements:
- âœ… Python 3.8+
- âœ… Docker Desktop
- âœ… kubectl
- âœ… Kubernetes cluster
- âœ… Helm (optional, will install if missing)
- âœ… System resources (RAM, disk)
- âœ… Network connectivity

**Usage:**
```bash
python setup/verify_prerequisites.py
```

---

### ğŸš€ **deploy_complete_stack.py**

Deploys the entire platform in one command:

1. Core Kubernetes resources (Sales + Marketing)
2. Helm + JupyterHub
3. Trino + Minio + Hive
4. Grafana + Nginx
5. Sample data

**Usage:**
```bash
python setup/deploy_complete_stack.py
```

**Time:** ~10-15 minutes  
**Requirements:** 8-10GB RAM

---

### ğŸ§¹ **cleanup.py**

Removes ALL deployed DataMeesh resources:
- Helm releases (JupyterHub)
- Kubernetes namespaces
- Persistent volumes
- StorageClasses
- PriorityClasses
- Docker images (DataMeesh related)
- Docker build cache
- Docker containers
- Docker volumes
- Docker networks
- Docker system cache

**Usage:**
```bash
python setup/cleanup.py
```

âš ï¸ **Warning:** This removes all DataMeesh resources!

---

### ğŸ§¹ **cleanup_docker_cache.py** (Advanced)

**ULTRA-AGGRESSIVE** Docker cleanup - removes ALL Docker resources:
- ALL containers (even non-DataMeesh)
- ALL images (even non-DataMeesh)
- ALL volumes
- ALL networks
- ALL build cache

**Usage:**
```bash
python setup/cleanup_docker_cache.py
```

âš ï¸ **DANGER:** This removes ALL Docker resources, not just DataMeesh!  
Use only if you want to completely clean Docker.

---

### ğŸ—‚ï¸ **datahub/deploy_datahub.py** (Optional)

**DataHub metadata catalog** - requires 10-12GB RAM:
- ALL containers (even non-DataMeesh)
- ALL images (even non-DataMeesh)
- ALL volumes
- Metadata catalog
- Data lineage visualization
- Dataset documentation

**Usage:**
```bash
python setup/datahub/deploy_datahub.py
```

âš ï¸ **Requirements:**
- Docker Desktop with 10-12GB RAM
- Base platform already deployed

**Access:** http://localhost:9002 (datahub / datahub)

---

## ğŸ¯ By-Technology Scripts

### Kubernetes

**File:** `kubernetes/deploy_k8s.py`

Deploys core domains:
- Sales domain (PostgreSQL + APIs)
- Marketing domain (PostgreSQL + APIs)
- Secrets & ConfigMaps
- Network Policies
- Resource Quotas
- Auto-scaling (HPA)

---

### Helm & JupyterHub

**Files:**
- `helm/install_helm.py` - Install Helm
- `helm/deploy_jupyterhub.py` - Deploy JupyterHub
- `helm/jupyterhub-values.yaml` - Configuration

Features:
- Multi-user notebooks
- Custom DBT image
- Trino client
- Git integration
- Scheduler extension

---

### Trino Stack

**File:** `trino/deploy_trino.py`

Deploys:
- Trino Coordinator
- Trino Worker
- Minio (S3 storage)
- Hive PostgreSQL
- Hive Metastore

Enables:
- Federated SQL queries
- Cross-domain analytics
- Data lake access

---

### Grafana

**File:** `grafana/deploy_grafana.py`

Deploys:
- Grafana dashboards
- Nginx (DBT docs server)

Pre-configured datasources:
- Sales PostgreSQL
- Marketing PostgreSQL
- Trino

---

### DBT

**Files:**
- `dbt/setup_dbt.py` - Setup DBT in JupyterHub
- `dbt/dbt_project.yml` - Project configuration
- `dbt/profiles.yml` - Connection profiles
- `dbt/models/` - Data models

Models included:
- `stg_sales__customers` - Customer staging
- `stg_sales__orders` - Orders staging
- `mart_sales__customer_lifetime_value` - CLV with RFM

---

### Data

**File:** `data/load_sample_data.py`

Loads realistic sample data:
- Sales: 15 customers, 10 products, 20 orders
- Marketing: 8 campaigns, 15 leads, 50 traffic records

---

### Docker

**File:** `docker/Dockerfile.jupyterhub-dbt`

Custom JupyterHub image with:
- DBT (core, Trino, PostgreSQL)
- Trino CLI
- MinIO client
- Python packages (pandas, matplotlib, etc.)
- Git integration
- JupyterLab extensions

---

## ğŸ”„ Workflow Examples

### Fresh Installation

```bash
# On a new machine
git clone <repo>
cd DataMeesh

# Verify system
python setup/verify_prerequisites.py

# Deploy everything
python setup/deploy_complete_stack.py

# Access JupyterHub
# Open http://localhost:30080
# Login: admin / datamesh2024
```

### Rebuilding

```bash
# Clean up
python setup/cleanup.py

# Redeploy
python setup/deploy_complete_stack.py
```

### Adding Just Trino

```bash
# If you only need Trino
python setup/trino/deploy_trino.py
```

---

## ğŸŒ Cross-Platform Support

All scripts work on:
- âœ… **Windows** (PowerShell)
- âœ… **WSL2** (Ubuntu/Debian)
- âœ… **macOS** (Homebrew)
- âœ… **Linux** (apt/yum)

**Detection is automatic!** Scripts adapt to your OS.

---

## ğŸ“– Script Naming Convention

| Prefix | Purpose | Example |
|--------|---------|---------|
| `verify_` | Check requirements | `verify_prerequisites.py` |
| `install_` | Install tools | `install_helm.py` |
| `deploy_` | Deploy resources | `deploy_k8s.py` |
| `setup_` | Configure/setup | `setup_dbt.py` |
| `load_` | Load data | `load_sample_data.py` |
| `cleanup` | Remove resources | `cleanup.py` |

---

## ğŸ“ Best Practices

### Portability

âœ… **DO:**
- Use Python for all scripts
- Detect OS automatically
- Use `kubectl` and platform-agnostic commands
- Handle errors gracefully

âŒ **DON'T:**
- Use shell scripts (.sh, .bat)
- Hard-code paths
- Assume specific OS

### Error Handling

All scripts:
- âœ… Check prerequisites
- âœ… Provide clear error messages
- âœ… Suggest solutions
- âœ… Allow continuation after failures

### Documentation

Each script includes:
- âœ… Clear docstring
- âœ… Step-by-step output
- âœ… Next steps guidance
- âœ… Access points

---

## ğŸ”§ Development

### Adding a New Component

1. Create directory: `setup/<component>/`
2. Add deployment script: `deploy_<component>.py`
3. Update `deploy_complete_stack.py` to include it
4. Document in this README

### Testing

```bash
# Test individual script
python setup/kubernetes/deploy_k8s.py

# Test full deployment
python setup/deploy_complete_stack.py

# Test cleanup
python setup/cleanup.py
```

---

## ğŸ“ Troubleshooting

### Script fails with "kubectl not found"

```bash
# Install kubectl
python setup/verify_prerequisites.py
# Follow installation instructions
```

### Pods in "Pending" state

```bash
# Check resources
kubectl describe pod <pod-name> -n <namespace>

# Increase Docker Desktop RAM:
# Docker Desktop â†’ Settings â†’ Resources â†’ Memory â†’ 10GB+
```

### "Cannot connect to cluster"

```bash
# Enable Kubernetes in Docker Desktop:
# Docker Desktop â†’ Settings â†’ Kubernetes â†’ Enable
```

---

## ğŸ“š Related Documentation

- [Main README](../README.md) - Project overview
- [Quick Start](../QUICK_START.md) - Fast deployment
- [Complete Guide](../docs/guides/COMPLETE_GUIDE.md) - Detailed guide
- [Architecture](../docs/architecture/) - Technical details

---

## âœ… Checklist for New Machine

- [ ] Install Docker Desktop
- [ ] Enable Kubernetes in Docker Desktop
- [ ] Install Python 3.8+
- [ ] Clone repository
- [ ] Run `python setup/verify_prerequisites.py`
- [ ] Run `python setup/deploy_complete_stack.py`
- [ ] Access http://localhost:30080

**Time to productive platform: ~20 minutes!**

---

**The setup directory is designed for maximum portability and ease of use. Deploy anywhere, anytime!** ğŸš€

